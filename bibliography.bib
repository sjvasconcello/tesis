% Intro
@article{intro1,
   abstract = {The aim of this paper is to reassess the current view of technological trends adopting a historical perspective. In our interpretation, the historical record provides some suggestive evidence for a more sceptical view of the notion of an emerging “fourth” industrial revolution. Indeed, even at an impressionistic glance, the recent developments in AI, communication and robotics that are marked as the core of the fourth industrial revolution, appear as a rather natural prolongation of the ICT macro-trajectories described in this paper. At the same time, to study the relation between technology and labour, we focus on the plant level as the most useful unit of analysis to consider the complex interaction between management systems, labour process and technological innovations. In this sense, we examine two Internet of Things’ technologies in order to underline the persistence of a fundamental trait of the capitalist mode of production, namely the exertion of control over workers. Consistently, we expect a continuity between newly emerging management practices and previous management systems, especially referring to the ones adopted during the ICT revolution.},
   author = {Armanda Cetrulo and Alessandro Nuvolari},
   doi = {10.1007/S40812-019-00132-Y/TABLES/1},
   issn = {19724977},
   issue = {3},
   journal = {Journal of Industrial and Business Economics},
   keywords = {Control,ICT revolution,Industry 4.0,Management system},
   month = {9},
   pages = {391-402},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Industry 4.0: revolution or hype? Reassessing recent technological trends and their impact on labour},
   volume = {46},
   url = {https://link.springer.com/article/10.1007/s40812-019-00132-y},
   year = {2019},
}

@article{intro2,
   abstract = {In March 2023, the release of GPT-4 and its application, Copilot, astounds the world and thrusts AI into the spotlight in industry, and academia. The incredible superiority of GPT-4 is demonstrated by its ability to achieve high scores on almost all mainstream academic and professional standard exams, Copilot’s capability to accomplish nearly all repetitive office work, and the rapid spread of its applications across massive areas of human society within weeks of its launch. These changes lead to the belief on the emergence of GPT-4 having a significant impact on academic research in the finance and accounting fields by establishing a consensus on the psychological acceptance of AI and rapidly eliminating technical barriers of using it. This paper presents practical examples to demonstrate GPT-4’s effectiveness in sentiment analysis, ESG analysis, corporate culture analysis, and Federal Reserve opinion analysis, and provides instructive recommendations for applying it in these subject areas.},
   author = {Yi Cao and Jia Zhai},
   doi = {10.1080/14765284.2023.2212434},
   issn = {14765292},
   issue = {2},
   journal = {Journal of Chinese Economic and Business Studies},
   pages = {177-191},
   publisher = {Routledge},
   title = {Bridging the gap–the impact of ChatGPT on financial research},
   volume = {21},
   url = {https://www.tandfonline.com/action/journalInformation?journalCode=rcea20},
   year = {2023},
}

@article{intro3,
   abstract = {Conversational AI models like ChatGPT, developed by OpenAI, are a testament to the rapid advancements in artificial intelligence and language processing capabilities. ChatGPT is a language model trained on massive amounts of data, capable of performing a range of language-related tasks, including answering questions, generating text, and even writing poems. Its impressive performance has attracted significant attention from both researchers and industry professionals, leading to its widespread use in a variety of applications. However, the deployment of conversational AI models like ChatGPT raises important ethical and social considerations. There are concerns about the potential for AI systems to perpetuate biases and stereotypes, and the impact they may have on employment. As such, it is crucial that the development and deployment of these models be guided by ethical considerations and principles. The potential benefits of conversational AI models like ChatGPT are significant and far-reaching. In the customer service sector, for example, they can provide 24/7 support and improve the overall customer experience. In the content creation and marketing industries, they can be used to generate high-quality content, freeing up human workers to focus on more creative and strategic tasks. Additionally, they have the potential to revolutionize the way we interact with technology, changing the way we communicate and access information. ChatGPT represents a significant breakthrough in the field of AI language processing, with the potential to transform various industries and improve our lives. However, it is essential that we approach its development and deployment with caution, taking into account the potential ethical and social implications. The continued growth and evolution of conversational AI models like ChatGPT will shape the future of human-computer interaction, and it is up to us to actively monitor and mitigate any adverse consequences. In this research we will be discussing about all of these topics.},
   author = {Puranjay Savar Mattas},
   doi = {10.55248/GENGPI.2023.4218},
   issue = {02},
   journal = {International Journal of Research Publication and Reviews},
   pages = {435-440},
   publisher = {Genesis Global Publication},
   title = {ChatGPT: A Study of AI Language Processing and its Implications},
   volume = {04},
   year = {2023},
}

@misc{google1,
   title = {¿Qué es la IA generativa y cuáles son sus aplicaciones?  |  Google Cloud},
   url = {https://cloud.google.com/use-cases/generative-ai?hl=es},
}


@article{ETL,
   abstract = {Resumen-La tarea de un diseñador de procesos de ETL involucra: (1) analizar las fuentes de datos existentes para encontrar la semántica oculta en ellas y (2) diseñar el flujo de trabajo que extraiga los datos desde las fuentes, repare sus inconsistencias, los transforme en un formato deseado, y, finalmente, los inserte en la bodega de datos. Con el propósito de facilitar esta tarea, se han desarrollado diferentes técnicas, dos categorías que sobresalen son: (a) Las inspiradas en los diagramas de flujo y de procesos y (b) las inspiradas en el paradigma de programación orientada a objetos (POO) y los diagramas de UML. En el presente artículo se expone un par de alternativas halladas en la literatura y se ilustra la técnica utilizada en el proyecto "Desarrollo de una solución de inteligencia de negocios para apoyar a la toma de decisiones en el Proyecto Círculos de Aprendizaje", explicando el porqué de su elección y cómo se usó. Palabras clave-Bodegas de Datos, Inteligencia de Negocios, Zona de Preparación de Datos, Proceso de ETL. Abstract-The task of a designer ETL process involves: (1) analyzing existing data sources to find the semantics hidden in them and (2) design workflow that extracts data from sources, repair its inconsistencies, transforms it into a desired format, and finally inserted into the data warehouse. In order to facilitate this task, different techniques have been developed, two categories that stand out are: (a) inspired flow diagrams and process and (b) those based on the paradigm of object-oriented programming (OOP) and diagrams in UML. This article presents a couple of alternatives found in the literature and illustrates the technique used in the project "Development of a business intelligence solution to support decision making in the Learning Circles Project," explaining why of their choice and how it was used Key Word-Business Intelligence, Data Warehouse, Data Staging Area, ETL Process. I. INTRODUCCIÓN El proceso de extracción, transformación y carga-ETL (Extraction, Transformation and Load) es una de las actividades técnicas más críticas en el desarrollo de soluciones de inteligencia de negocios-BI (Business Intelligence) [1][2]. Hace parte del componente de integración y, de su implementación adecuada dependen la integridad, uniformidad, consistencia y disponibilidad de los datos utilizados en el componente de análisis de una solución de BI. Su función es extraer, limpiar, transformar, resumir, y formatear los datos que se almacenarán en la bodega de datos de la solución de BI [3][4][5]. La construcción del ETL puede dividirse en tres subprocesos o componentes: componente de extracción, componente de transformación y componente de carga. En la Tabla 1 se presenta la descripción de cada uno de estos componentes identificando los elementos objetivo, las operaciones realizadas, y los resultados esperados.},
   author = {Alexander Bustamante Martínez and Ernesto Amaru and Galvis Lista and Luis Carlos Gómez Flórez},
   issn = {0122-1701},
   issue = {1},
   journal = {Scientia et Technica Año XVIII},
   month = {3},
   title = {ETL Processes modeling techniques: an alternatives review and its application in a BI solution development project},
   volume = {18},
   year = {2013},
}

@misc{BuscadorAmbiental,
   title = {Buscador Ambiental},
   url = {https://www.buscadorambiental.cl/buscador/#/},
}

@misc{Ley20600,
   title = {Ley Chile - Ley 20600 - Biblioteca del Congreso Nacional},
   url = {https://www.bcn.cl/leychile/navegar?idNorma=1041361&idParte=9269911},
}

% ETL
@article{ETL1,
   abstract = {In this paper, we discuss the state of the art and current trends in designing and optimizing ETL workflows. We explain the existing techniques for: (1) constructing a conceptual and a logical model of an ETL workflow, (2) its corresponding physical implementation, and (3) its optimization, illustrated by examples. The discussed techniques are analyzed w.r.t. their advantages, disadvantages, and challenges in the context of metrics such as autonomous behavior, support for quality metrics, and support for ETL activities as user-defined functions. We draw conclusions on still open research and technological issues in the field of ETL. Finally, we propose a theoretical ETL framework for ETL optimization.},
   author = {Syed Muhammad Fawad Ali and Robert Wrembel},
   doi = {10.1007/S00778-017-0477-2/FIGURES/18},
   issn = {0949877X},
   issue = {6},
   journal = {VLDB Journal},
   keywords = {ETL conceptual design,ETL logical design,ETL optimization,ETL physical implementation,ETL workflow},
   month = {12},
   pages = {777-801},
   publisher = {Springer New York LLC},
   title = {From conceptual design to performance optimization of ETL workflows: current state of research and open problems},
   volume = {26},
   url = {https://link.springer.com/article/10.1007/s00778-017-0477-2},
   year = {2017},
}


@article{riego1,
   author = {Philip Feldman and James R. Foulds and Shimei Pan},
   isbn = {2306.06085v1},
   month = {6},
   title = {Trapping LLM Hallucinations Using Tagged Context Prompts},
   url = {https://arxiv.org/abs/2306.06085v1},
   year = {2023},
}


@article{langchain1,
   abstract = {ChatGPT is a type of language model that uses machine learning algorithms to generate responses to natural language input. Its advanced technology can revolutionize the way humans interact with machines by creating more natural and intuitive communication. However, the accuracy of ChatGPT's responses may be compromised by biased or inaccurate data, which highlights the importance of carefully evaluating its output. Furthermore, early versions of ChatGPT were found to produce academic papers with missing references, which may compromise the credibility of research in the academic publishing industry. This underscores the need to establish regulations and guidelines that ensure the ethical and transparent use of these technologies, and to avoid relying solely on automated tools like ChatGPT without thoroughly reviewing the literature. In order to minimise the potential for inaccurate information in the classroom, an intuitive application based on the AI language (OpenAI-also used by ChatGPT) has been implemented. The application has been designed in such a way that it does not use internet databases as a search source and the answers to the questions are based on pre-established documentation that has been checked/certified by the educational institution/professors. The developed application can be installed either locally on a personal computer or on a file server/online library etc. and does not require access to a reliable Internet connection as in the case of ChatGPT.},
   author = {Mirela Șorecău and Emil Șorecău},
   doi = {10.2478/kbo-2023-0084},
   keywords = {template},
   pages = {2023},
   title = {AN ALTERNATIVE APPLICATION TO CHATGPT THAT USES RELIABLE SOURCES TO ENHANCE THE LEARNING PROCESS},
   volume = {XXIX},
   year = {2023},
}

@article{raq,
   abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG)-models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
   author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
   journal = {Advances in Neural Information Processing Systems},
   pages = {9459-9474},
   title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
   volume = {33},
   url = {https://github.com/huggingface/transformers/blob/master/},
   year = {2020},
}

@article{mapreduce,
   abstract = {Document summarization provides an instrument for faster understanding the collection of text documents and has a number of real life applications. Semantic similarity and clustering can be utilized efficiently for generating effective summary of large text collections. Summarizing large volume of text is a challenging and time consuming problem particularly while considering the semantic similarity computation in summarization process. Summarization of text collection involves intensive text processing and computations to generate the summary. MapReduce is proven state of art technology for handling Big Data. In this paper, a novel framework based on MapReduce technology is proposed for summarizing large text collection. The proposed technique is designed using semantic similarity based clustering and topic modeling using Latent Dirichlet Allocation (LDA) for summarizing the large text collection over MapReduce framework. The summarization task is performed in four stages and provides a modular implementation of multiple documents summarization. The presented technique is evaluated in terms of scalability and various text summarization parameters namely, compression ratio, retention ratio, ROUGE and Pyramid score are also measured. The advantages of MapReduce framework are clearly visible from the experiments and it is also demonstrated that MapReduce provides a faster implementation of summarizing large text collections and is a powerful tool in Big Text Data analysis.},
   author = {N. K. Nagwani},
   doi = {10.1186/S40537-015-0020-5/FIGURES/15},
   issn = {21961115},
   issue = {1},
   journal = {Journal of Big Data},
   keywords = {Big Text Data analysis,Clustering based summarization,Semantic similarity,Summarizing large text,Text clustering},
   month = {12},
   pages = {1-18},
   publisher = {SpringerOpen},
   title = {Summarizing large text collection using topic modeling and clustering based on MapReduce framework},
   volume = {2},
   url = {https://link.springer.com/articles/10.1186/s40537-015-0020-5 https://link.springer.com/article/10.1186/s40537-015-0020-5},
   year = {2015},
}

@misc{openai1,
   author = {OpenAI},
   title = {Embeddings - OpenAI API},
   url = {https://platform.openai.com/docs/guides/embeddings/what-are-embeddings},
}

@misc{openai2,
   author = {OpenAI},
   title = {Introducing GPTs},
   url = {https://openai.com/blog/introducing-gpts},
}

@misc{openai3,
   author = {OpenAI},
   title = {New models and developer products announced at DevDay},
   url = {https://openai.com/blog/new-models-and-developer-products-announced-at-devday},
}

@misc{billgates1,
   author = {Mrwhosetheboss},
   title = {Can AI really save the World? ft. Bill Gates - YouTube},
   url = {https://www.youtube.com/watch?v=l9m3IKG8i88&t=16s},
}

@inproceedings{sesgo2,
    title = "Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts",
    author = "Guo, Yue  and
      Yang, Yi  and
      Abbasi, Ahmed",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.72",
    doi = "10.18653/v1/2022.acl-long.72",
    pages = "1012--1023",
    abstract = "Human-like biases and undesired social stereotypes exist in large pretrained language models. Given the wide adoption of these models in real-world applications, mitigating such biases has become an emerging and important task. In this paper, we propose an automatic method to mitigate the biases in pretrained language models. Different from previous debiasing work that uses external corpora to fine-tune the pretrained models, we instead directly probe the biases encoded in pretrained models through prompts. Specifically, we propose a variant of the beam search method to automatically search for \textit{biased prompts} such that the cloze-style completions are the most different with respect to different demographic groups. Given the identified biased prompts, we then propose a distribution alignment loss to mitigate the biases. Experiment results on standard datasets and metrics show that our proposed \textbf{Auto-Debias} approach can significantly reduce biases, including gender and racial bias, in pretrained language models such as BERT, RoBERTa and ALBERT. Moreover, the improvement in fairness does not decrease the language models{'} understanding abilities, as shown using the GLUE benchmark.",
}

@article{modelos1,
   abstract = {As organizations strive to integrate these models into their systems, the pivotal challenge they face is selecting the most appropriate alternative. The task of selecting an appropriate LLM for organizational integration remains complex. This paper presents a comprehensive analysis of factors that should be considered when choosing a LLM, aiming to align the selected model with specific organizational goals. The comparison involves five prominent LLMs: ChatGPT, Bard, Lamma, Hugging Face, and GitHub Copilot. The findings highlight the significance of certain factors in LLM selection. Pre-training data diversity, as observed in ChatGPT and Bard, enhances language coverage and response accuracy. Larger models, like ChatGPT and Bard, exhibit superior comprehension and logical responses due to their extensive parameter count. Training time considerations are crucial, with models such as Bard and Lamma requiring months for training, while Hugging Face and GitHub Copilot offer faster training periods. Language support emerges as a key determinant based on organizational needs. Models like Lamma focus on scientific language, while ChatGPT and Bard emphasize broad language coverage. Enterprise readiness, user data control, and real-time research capabilities are pivotal in decision-making. The study also reveals distinctions in model purposes, API capabilities, user feedback mechanisms, and cloud provider support.},
   author = {Shreekant Mandvikar},
   issue = {3},
   journal = {International Journal of Intelligent Automation and Computing},
   keywords = {Enterprise Readiness,Language Model Selection,Large Language Models,Natural Language Processing},
   month = {8},
   pages = {37-40},
   title = {Factors to Consider When Selecting a Large Language Model: A Comparative Analysis},
   volume = {6},
   url = {https://research.tensorgate.org/index.php/IJIAC/article/view/53},
   year = {2023},
}
@misc{modelos2,
   author = {Meta},
   title = {Llama 2 - Meta AI},
   url = {https://ai.meta.com/llama/},
}
@misc{modelos3,
   author = {Lakera},
   title = {The List of 11 Most Popular Open Source LLMs of 2023 | Lakera – Protecting AI teams that disrupt the world.},
   url = {https://www.lakera.ai/blog/open-source-llms},
}

@article{RLHF,
   abstract = {We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound for max-entropy IRL.},
   author = {Banghua Zhu and Jiantao Jiao and Michael I. Jordan},
   issn = {26403498},
   month = {1},
   title = {Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons},
   url = {https://arxiv.org/abs/2301.11270v4},
   year = {2023},
}

@article{alucionacion1,
   abstract = {As large language models continue to develop in the field of AI, text
generation systems are susceptible to a worrisome phenomenon known as
hallucination. In this study, we summarize recent compelling insights into
hallucinations in LLMs. We present a novel taxonomy of hallucinations from
various text generation tasks, thus provide theoretical insights, detection
methods and improvement approaches. Based on this, future research directions
are proposed. Our contribution are threefold: (1) We provide a detailed and
complete taxonomy for hallucinations appearing in text generation tasks; (2) We
provide theoretical analyses of hallucinations in LLMs and provide existing
detection and improvement methods; (3) We propose several research directions
that can be developed in the future. As hallucinations garner significant
attention from the community, we will maintain updates on relevant research
progress.},
   author = {Hongbin Ye and Tong Liu and Aijia Zhang and Wei Hua and Weiqiang Jia and Zhejiang Lab},
   month = {9},
   title = {Cognitive Mirage: A Review of Hallucinations in Large Language Models},
   url = {https://arxiv.org/abs/2309.06794v1},
   year = {2023},
}

@article{coseno,
   abstract = {Cosine similarity of contextual embeddings is used in many NLP tasks (e.g., QA, IR, MT) and metrics (e.g., BERTScore). Here, we uncover systematic ways in which word similarities estimated by cosine over BERT embeddings are understated and trace this effect to training data frequency. We find that relative to human judgements, cosine similarity underestimates the similarity of frequent words with other instances of the same word or other words across contexts, even after controlling for polysemy and other factors. We conjecture that this underestimation of similarity for high frequency words is due to differences in the representational geometry of high and low frequency words and provide a formal argument for the two-dimensional case.},
   author = {Kaitlyn Zhou and Kawin Ethayarajh and Dallas Card and Dan Jurafsky},
   doi = {10.18653/v1/2022.acl-short.45},
   isbn = {9781955917223},
   issn = {0736587X},
   journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
   month = {5},
   pages = {401-423},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words},
   volume = {2},
   url = {https://arxiv.org/abs/2205.05092v1},
   year = {2022},
}


@article{privacidad1,
   abstract = {Given access to a machine learning model, can an adversary reconstruct the model's training data? This work studies this question from the lens of a powerful informed adversary who knows all the training data points except one. By instantiating concrete attacks, we show it is feasible to reconstruct the remaining data point in this stringent threat model. For convex models (e.g. logistic regression), reconstruction attacks are simple and can be derived in closed-form. For more general models (e.g. neural networks), we propose an attack strategy based on training a reconstructor network that receives as input the weights of the model under attack and produces as output the target data point. We demonstrate the effectiveness of our attack on image classifiers trained on MNIST and CIFAR-10, and systematically investigate which factors of standard machine learning pipelines affect reconstruction success. Finally, we theoretically investigate what amount of differential privacy suffices to mitigate reconstruction attacks by informed adversaries. Our work provides an effective reconstruction attack that model developers can use to assess memorization of individual points in general settings beyond those considered in previous works (e.g. generative language models or access to training gradients); it shows that standard models have the capacity to store enough information to enable high-fidelity reconstruction of training data points; and it demonstrates that differential privacy can successfully mitigate such attacks in a parameter regime where utility degradation is minimal.},
   author = {Borja Balle and Giovanni Cherubin and Jamie Hayes},
   doi = {10.1109/SP46214.2022.9833677},
   isbn = {9781665413169},
   issn = {10816011},
   journal = {Proceedings - IEEE Symposium on Security and Privacy},
   keywords = {differential privacy,machine learning,neural networks,reconstruction attacks},
   pages = {1138-1156},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Reconstructing Training Data with Informed Adversaries},
   volume = {2022-May},
   year = {2022},
}

@misc{privacidad2,
   author = {Infobae},
   title = {Escritor de Juego de Tronos demanda a OpenAI por “robo sistemático”},
   url = {https://www.infobae.com/tecno/2023/09/23/escritor-de-juego-de-tronos-demanda-a-openai-por-robo-sistematico/},
}


@misc{privacidad3,
   author = {WIRED},
   title = {Comediante Sarah Silverman demanda a OpenAI y Meta por infringir derechos de autor},
   url = {https://es.wired.com/articulos/sarah-silverman-demanda-a-openai-y-meta-por-infringir-derechos-de-autor},
}

@misc{openai4,
   author = {OpenAI},
   title = {Introducing ChatGPT Enterprise},
   url = {https://openai.com/blog/introducing-chatgpt-enterprise},
}

@misc{microsoft1,
   author = {Microsoft Learn},
   title = {LLM AI Embeddings},
   url = {https://learn.microsoft.com/en-us/semantic-kernel/memories/embeddings},
}

@article{ft1,
  title={Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation},
  author={Huang, Kai and Yin, Hanyun and Huang, Heng and Gao, Wei},
  journal={arXiv preprint arXiv:2309.13192},
  year={2023}
}

@article{calidad1,
   abstract = {Deep learning has been widely used for extracting values from big data. As many other Machine learning algorithms, deep learning requires significant training data. Experiments have shown both the volume and the quality of training data can significantly impact the effectiveness of the value extraction. In some cases, the volume of training data is not sufficiently large for effectively training a deep learning model. In other cases, the quality of training data is not high enough to achieve the optimal performance. Many approaches have been proposed for augmenting training data to mitigate the deficiency. However, whether the augmented data are “fit for purpose” of deep learning is still a question. A framework for comprehensively evaluating the effectiveness of the augmented data for deep learning is still not available. In this article, we first discuss a data augmentation approach for deep learning. The approach includes two components: the first one is to remove noisy data in a dataset using a Machine learning based classification to improve its quality, and the second one is to increase the volume of the dataset for effectively training a deep learning model. To evaluate the quality of the augmented data in fidelity, variety, and veracity, a data quality evaluation framework is proposed. We demonstrated the effectiveness of the data augmentation approach and the data quality evaluation framework through studying an automated classification of biology cell images using deep learning. The experimental results clearly demonstrated the impact of the volume and quality of training data to the performance of deep learning and the importance of the data quality evaluation. The data augmentation approach and the data quality evaluation framework can be straightforwardly adapted for deep learning study in other domains.},
   author = {Junhua Ding and Xinchuan Li and Xiaojun Kang and Venkat N. Gudivada},
   doi = {10.1145/3317573},
   issn = {19361963},
   issue = {4},
   journal = {Journal of Data and Information Quality},
   keywords = {Convolutional neural network,Data quality,Deep learning,Diffraction image,Machine learning,Support vector Machine},
   month = {8},
   publisher = {Association for Computing Machinery},
   title = {A case study of the augmentation and evaluation of training data for deep learning},
   volume = {11},
   url = {https://doi.org/10.1145/3317573},
   year = {2019},
}

@misc{framework1,
  author = {Chase, Harrison},
  title = {Welcome to LangChain},
  year = {2022},
  howpublished = {https://langchain-doc.readthedocs.io/en/latest/index.html},
  note = {Accessed: 2023-11-06}
}


@article{datos1,
   abstract = {Data analysis is an interdisciplinary science. Traditionally its development has been driven by the areas of application, but nowadays its development is also stimulated by the ever-changing possibilities promised by progress in computer technology. Huge data sets and non-numerical data, such as text data, image data, and metadata, present both challenges and opportunities for modern data analysts. These in turn lead to new types of problems and require the development of new types of models. Intelligent data analysis also requires that one take proper advantage of the largely complementary abilities of humans and computers. Interactive graphics, an important tool for modern intelligent data analysis, nicely illustrates this: the production of such graphics, and the ability to manipulate them in real time, requires advanced computational facilities; but the ability to interpret them requires the capacity to synthesise possessed only by the human eye and mind. Intelligent data analysis also requires one to have a proper strategy for analysis. Analysis without strategy is surely one of the hallmarks of unintelligent data analysis. Likewise, a key to intelligent data analysis is the ability to recognise what is important in a problem—what counts and what doesn't count.},
   author = {D HAND},
   doi = {10.1016/S1088-467X(99)80001-8},
   issn = {1088-467X},
   issue = {1-4},
   journal = {Intelligent Data Analysis},
   month = {1},
   pages = {67-79},
   publisher = {No longer published by Elsevier},
   title = {Intelligent data analysis: Issues and opportunities},
   volume = {2},
   year = {1998},
}

@article{datos2,
   abstract = {Understanding how species are distributed in the environment is increasingly important for natural resource management, particularly for keystone and habitat – forming species, and those of conservation concern. Habitat suitability models are fundamental to developing this understanding; however their use in management continues to be limited due to often-vague model objectives and inadequate evaluation methods. Along the Northeast Pacific coast, canopy kelps (Macrocystis pyrifera and Nereocystis luetkeana) provide biogenic habitat and considerable primary production to nearshore ecosystems. We investigated the distribution of these species by examining a series of increasingly complex habitat suitability models ranging from process-based models based on species’ ecology to complex generalised additive models applied to purpose-collected survey data. Seeking empirical limits to model complexity, we explored the relationship between model complexity and forecast skill, measured using both cross-validation and independent data evaluation. Our analysis confirmed the importance of predictors used in models of coastal kelp distributions developed elsewhere (i.e. depth, bottom type, bottom slope, and exposure); it also identified additional important factors including salinity, and potential interactions between exposure and salinity, and slope and tidal energy. Comparative results showed how cross-validation can lead to over-fitting, while independent data evaluation clearly identified the appropriate model complexity for generating habitat forecasts. Our results also illustrate that, depending on the evaluation data, predictions from simpler models can out-perform those from more complex models. Collectively, the insights from evaluating multiple models with multiple data sets contribute to the holistic assessment of model forecast skill. The continued development of methods and metrics for evaluating model forecasts with independent data, and the explicit consideration of model objectives and assumptions, promise to increase the utility of model forecasts to decision makers.},
   author = {Edward J. Gregr and Daniel M. Palacios and Allison Thompson and Kai M.A. Chan},
   doi = {10.1111/ECOG.03470},
   issn = {16000587},
   issue = {3},
   journal = {Ecography},
   keywords = {coastal ecosystem,forecast skill,habitat suitability},
   month = {3},
   pages = {428-443},
   publisher = {Blackwell Publishing Ltd},
   title = {Why less complexity produces better forecasts: an independent data evaluation of kelp habitat models},
   volume = {42},
   year = {2019},
}

@misc{conclusion1,
   author = {Yahoo Finance},
   title = {Nvidia’s CEO just gave a graduation speech about the future of work and said that A.I. won’t steal jobs but ‘someone who’s an expert with A.I. will’},
   url = {https://finance.yahoo.com/news/nvidia-ceo-just-gave-graduation-183507133.html},
   year = {2023},
}

@misc{conclusion2,
      title={Large Language Models as Optimizers}, 
      author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le and Denny Zhou and Xinyun Chen},
      year={2023},
      eprint={2309.03409},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{conclusion3,
      title={Promptbreeder: Self-Referential Self-Improvement via Prompt Evolution}, 
      author={Chrisantha Fernando and Dylan Banarse and Henryk Michalewski and Simon Osindero and Tim Rocktäschel},
      year={2023},
      eprint={2309.16797},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{aiayn,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mt1,
  title={Artificial Intelligence's Role in Finance and How Financial Companies are Leveraging the Technology to Their Advantage},
  author={Whitney Hunt and Kendal Marshall and Ryan Perry},
  year={2020},
  publisher={University of Charleston},
  note={Disponible en SSRN: https://ssrn.com/abstract=3707908}
}

@article{mt2,
  title={Generative artificial intelligence: Trends and prospects},
  author={Jovanovic, Mladan and Campbell, Mark},
  journal={Computer},
  volume={55},
  number={10},
  pages={107--112},
  year={2022},
  publisher={IEEE Computer Society}
}

@article{perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}


@misc{mt3,
  title = {Introducing ChatGPT},
  author = {OpenAI},
  year = {2022},
  month = {11},
  howpublished = {\url{https://openai.com/blog/chatgpt}},
  note = {Accessed: 2023-11-16}
}

@article{nlpeda,
  title={Natural language processing},
  author={Chopra, Abhimanyu and Prashar, Abhinav and Sain, Chandresh},
  journal={International journal of technology enhancements and emerging engineering research},
  volume={1},
  number={4},
  pages={131--134},
  year={2013},
  publisher={Citeseer}
}


@article{mt4,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{mt5,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{mt6,
  title={Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?},
  author={Alberts, Ian L and Mercolli, Lorenzo and Pyka, Thomas and Prenosil, George and Shi, Kuangyu and Rominger, Axel and Afshar-Oromieh, Ali},
  journal={European journal of nuclear medicine and molecular imaging},
  volume={50},
  number={6},
  pages={1549--1552},
  year={2023},
  publisher={Springer}
}

@article{eb1,
  title = {Text and Code Embeddings by Contrastive Pre-Training},
  author = {Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford, Alec and Han, Jesse Michael and Tworek, Jerry and Yuan, Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy, Chris and others},
  year = {2022},
  month = {01},
  volume = {arXiv:2201.10005},
  journal = {arXiv preprint arXiv:2201.10005},
  url = {https://ar5iv.org/abs/2201.10005}
}

@misc{eb2,
  title = {Introducing text and code embeddings},
  author = {Neelakantan, Arvind and Weng, Lilian},
  year = {2022},
  month = {01},
  howpublished = {\url{https://openai.com/blog/introducing-text-and-code-embeddings}},
  note = {Accessed: 2023-11-16}
}

@misc{eb3,
  title = {What are Embeddings},
  author = {OpenAI},
  year = {2023},
  month = {11},
  howpublished = {\url{https://platform.openai.com/docs/guides/embeddings/what-are-embeddings}},
  note = {Accessed: 2023-11-16}
}

@misc{p1,
   author = {La Tercera},
   title = {SEA pide a Tribunal Ambiental rechazar reclamación de Andes Iron por Dominga},
   url = {https://www.latercera.com/pulso-pm/noticia/sea-pide-a-tribunal-ambiental-rechazar-reclamacion-de-andes-iron-por-dominga-y-acusa-a-la-minera-de-permanente-victimizacion/ZJ6KKJLV6ZDJFM6YKGAUF6PP7E/},
}

@misc{p2,
   author = {Tribunal Ambiental},
   title = {Tribunal escuchó alegatos en 7 reclamaciones que buscan anular la aprobación ambiental del proyecto minero Blanco},
   url = {https://tribunalambiental.cl/audiencia-r-333-2022-acumula-6-rca-proyecto-blanco-atacama/},
}

@online{p3,
    author = {Diario Financiero},
    title = {PAPEL DIGITAL},
    url = {https://www.df.cl/empresas/energia/hidroaysen-sufre-reves-judicial-en-defensa-de-derechos-de-agua},
    urldate = {2023-11-19}
}

@article{eb4,
   abstract = {In the past few years we have seen the meteoric appearance of dozens of foundation models of the Transformer family, all of which have memorable and sometimes funny, but not self-explanatory, names. The goal of this paper is to offer a somewhat comprehensive but simple catalog and classification of the most popular Transformer models. The paper also includes an introduction to the most important aspects and innovations in Transformer models. Our catalog will include models that are trained using self-supervised learning (e.g., BERT or GPT3) as well as those that are further trained using a human-in-the-loop (e.g. the InstructGPT model used by ChatGPT).},
   author = {Xavier Amatriain and Xavier@amatriain Net and Ananth Sankar and Jie Bing and Praveen Kumar Bodigutla and Timothy J Hazen and Michaeel Kazi},
   month = {2},
   title = {Transformer models: an introduction and catalog},
   url = {https://arxiv.org/abs/2302.07730v3},
   year = {2023},
}


@article{intro1,
   abstract = {There is a great deal of concern expressed by many in the artificial intelligence (AI) community about the existential risk of this rapidly developing technology. This paper provides a discussion on some issues that need to be addressed to handle potential future risks and provides some new perspectives. The development of artificial intelligence is moving from relatively limited standalone to large-scale, complex distributed systems. However, potential risks such as malfunction, malicious attacks and mismatch of objective can occur from hardware and software failures or design errors. Moreover, a system controlled by high level AI can become unpredictable in its behaviours and thus ethical risks can emerge when such systems have to make a decision related to operational issues. Given that all new, disruptive, technologies have risks associated with them, what we need to do, as practitioners and users, is to find ways of mitigating those risks. We discuss applications of agent-based simulation to illustrate some of the risks and, potentially, how to mitigate them.},
   author = {John Page and Michael Bain and Faqihza Mukhlish},
   doi = {10.1109/IISR.2018.8535903},
   isbn = {9781538655467},
   journal = {2018 International Conference on Intelligence and Safety for Robotics, ISR 2018},
   month = {11},
   pages = {1-6},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {The Risks of Low Level Narrow Artificial Intelligence},
   year = {2018},
}

@misc{Kaspersky_2023, 
   title={What are bots? - definition and explanation}, 
   url={https://www.kaspersky.com/resource-center/definitions/what-are-bots}, 
   journal={www.kaspersky.com}, 
   author={Kaspersky}, 
   year={2023}, 
   month={April},
} 

@misc{seleniumSelenium,
	author = {Selenium },
	title = {Selenium - selenium.dev},
	howpublished = {\url{https://www.selenium.dev/}},
	note = {Acceso en 25-11-2023},
}

@misc{techtargetWhatScript,
	author = {},
	title = {{W}hat is script? | {D}efinition from {T}ech{T}arget --- techtarget.com},
	howpublished = {\url{https://www.techtarget.com/whatis/definition/script}},
	year = {},
	note = {[Accessed 25-11-2023]},
}

@misc{openaimodels,
	author = {OpenAI},
	title = {{M}odels},
	howpublished = {\url{https://platform.openai.com/docs/models/}},
	year = {2023},
	note = {[Accessed 25-11-2023]},
}

@misc{trychromaAInativeOpensource,
	author = {ChormaDB},
	title = {the {A}{I}-native open-source embedding database --- trychroma.com},
	howpublished = {\url{https://www.trychroma.com/}},
	year = {},
	note = {[Accessed 25-11-2023]},
}

@misc{pythonWelcomePythonorg,
	author = {Python Software Foundation},
	title = {{W}elcome to {P}ython.org --- python.org},
	howpublished = {\url{https://www.python.org/}},
	note = {[Accessed 25-11-2023]},
}

@misc{flask1,
	author = {Werkzeug},
	title = {{W}elcome to {F}lask; {F}lask {D}ocumentation (3.0.x) --- flask.palletsprojects.com},
	howpublished = {\url{https://flask.palletsprojects.com/en/3.0.x/}},
	note = {[Accessed 25-11-2023]},
}

@misc{tiangoloFastAPI,
	author = {Tiagolo},
	title = {{F}ast{A}{P}{I} --- fastapi.tiangolo.com},
	howpublished = {\url{https://fastapi.tiangolo.com/}},
	note = {[Accessed 25-11-2023]},
}


@misc{swaggerAPIDocumentation,
	author = {Swagger},
	title = { 	{A}{P}{I} {D}ocumentation \&amp; {D}esign {T}ools for {T}eams | {S}wagger  --- swagger.io},
	howpublished = {\url{https://swagger.io/}},
	year = {},
	note = {[Accessed 25-11-2023]},
}


@inproceedings{prompt,
author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
title = {Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581388},
doi = {10.1145/3544548.3581388},
abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {21},
keywords = {end-users, design tools, language models},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}

@inproceedings{chatbot_def,
  title={An overview of chatbot technology},
  author={Adamopoulou, Eleni and Moussiades, Lefteris},
  booktitle={IFIP international conference on artificial intelligence applications and innovations},
  pages={373--383},
  year={2020},
  organization={Springer}
}
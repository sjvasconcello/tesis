% Intro
@article{intro1,
   abstract = {The aim of this paper is to reassess the current view of technological trends adopting a historical perspective. In our interpretation, the historical record provides some suggestive evidence for a more sceptical view of the notion of an emerging “fourth” industrial revolution. Indeed, even at an impressionistic glance, the recent developments in AI, communication and robotics that are marked as the core of the fourth industrial revolution, appear as a rather natural prolongation of the ICT macro-trajectories described in this paper. At the same time, to study the relation between technology and labour, we focus on the plant level as the most useful unit of analysis to consider the complex interaction between management systems, labour process and technological innovations. In this sense, we examine two Internet of Things’ technologies in order to underline the persistence of a fundamental trait of the capitalist mode of production, namely the exertion of control over workers. Consistently, we expect a continuity between newly emerging management practices and previous management systems, especially referring to the ones adopted during the ICT revolution.},
   author = {Armanda Cetrulo and Alessandro Nuvolari},
   doi = {10.1007/S40812-019-00132-Y/TABLES/1},
   issn = {19724977},
   issue = {3},
   journal = {Journal of Industrial and Business Economics},
   keywords = {Control,ICT revolution,Industry 4.0,Management system},
   month = {9},
   pages = {391-402},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Industry 4.0: revolution or hype? Reassessing recent technological trends and their impact on labour},
   volume = {46},
   url = {https://link.springer.com/article/10.1007/s40812-019-00132-y},
   year = {2019},
}

@article{intro2,
   abstract = {In March 2023, the release of GPT-4 and its application, Copilot, astounds the world and thrusts AI into the spotlight in industry, and academia. The incredible superiority of GPT-4 is demonstrated by its ability to achieve high scores on almost all mainstream academic and professional standard exams, Copilot’s capability to accomplish nearly all repetitive office work, and the rapid spread of its applications across massive areas of human society within weeks of its launch. These changes lead to the belief on the emergence of GPT-4 having a significant impact on academic research in the finance and accounting fields by establishing a consensus on the psychological acceptance of AI and rapidly eliminating technical barriers of using it. This paper presents practical examples to demonstrate GPT-4’s effectiveness in sentiment analysis, ESG analysis, corporate culture analysis, and Federal Reserve opinion analysis, and provides instructive recommendations for applying it in these subject areas.},
   author = {Yi Cao and Jia Zhai},
   doi = {10.1080/14765284.2023.2212434},
   issn = {14765292},
   issue = {2},
   journal = {Journal of Chinese Economic and Business Studies},
   pages = {177-191},
   publisher = {Routledge},
   title = {Bridging the gap–the impact of ChatGPT on financial research},
   volume = {21},
   url = {https://www.tandfonline.com/action/journalInformation?journalCode=rcea20},
   year = {2023},
}

@article{intro3,
   abstract = {Conversational AI models like ChatGPT, developed by OpenAI, are a testament to the rapid advancements in artificial intelligence and language processing capabilities. ChatGPT is a language model trained on massive amounts of data, capable of performing a range of language-related tasks, including answering questions, generating text, and even writing poems. Its impressive performance has attracted significant attention from both researchers and industry professionals, leading to its widespread use in a variety of applications. However, the deployment of conversational AI models like ChatGPT raises important ethical and social considerations. There are concerns about the potential for AI systems to perpetuate biases and stereotypes, and the impact they may have on employment. As such, it is crucial that the development and deployment of these models be guided by ethical considerations and principles. The potential benefits of conversational AI models like ChatGPT are significant and far-reaching. In the customer service sector, for example, they can provide 24/7 support and improve the overall customer experience. In the content creation and marketing industries, they can be used to generate high-quality content, freeing up human workers to focus on more creative and strategic tasks. Additionally, they have the potential to revolutionize the way we interact with technology, changing the way we communicate and access information. ChatGPT represents a significant breakthrough in the field of AI language processing, with the potential to transform various industries and improve our lives. However, it is essential that we approach its development and deployment with caution, taking into account the potential ethical and social implications. The continued growth and evolution of conversational AI models like ChatGPT will shape the future of human-computer interaction, and it is up to us to actively monitor and mitigate any adverse consequences. In this research we will be discussing about all of these topics.},
   author = {Puranjay Savar Mattas},
   doi = {10.55248/GENGPI.2023.4218},
   issue = {02},
   journal = {International Journal of Research Publication and Reviews},
   pages = {435-440},
   publisher = {Genesis Global Publication},
   title = {ChatGPT: A Study of AI Language Processing and its Implications},
   volume = {04},
   year = {2023},
}

@misc{google1,
   title = {¿Qué es la IA generativa y cuáles son sus aplicaciones?  |  Google Cloud},
   url = {https://cloud.google.com/use-cases/generative-ai?hl=es},
}


@article{ETL,
   abstract = {Resumen-La tarea de un diseñador de procesos de ETL involucra: (1) analizar las fuentes de datos existentes para encontrar la semántica oculta en ellas y (2) diseñar el flujo de trabajo que extraiga los datos desde las fuentes, repare sus inconsistencias, los transforme en un formato deseado, y, finalmente, los inserte en la bodega de datos. Con el propósito de facilitar esta tarea, se han desarrollado diferentes técnicas, dos categorías que sobresalen son: (a) Las inspiradas en los diagramas de flujo y de procesos y (b) las inspiradas en el paradigma de programación orientada a objetos (POO) y los diagramas de UML. En el presente artículo se expone un par de alternativas halladas en la literatura y se ilustra la técnica utilizada en el proyecto "Desarrollo de una solución de inteligencia de negocios para apoyar a la toma de decisiones en el Proyecto Círculos de Aprendizaje", explicando el porqué de su elección y cómo se usó. Palabras clave-Bodegas de Datos, Inteligencia de Negocios, Zona de Preparación de Datos, Proceso de ETL. Abstract-The task of a designer ETL process involves: (1) analyzing existing data sources to find the semantics hidden in them and (2) design workflow that extracts data from sources, repair its inconsistencies, transforms it into a desired format, and finally inserted into the data warehouse. In order to facilitate this task, different techniques have been developed, two categories that stand out are: (a) inspired flow diagrams and process and (b) those based on the paradigm of object-oriented programming (OOP) and diagrams in UML. This article presents a couple of alternatives found in the literature and illustrates the technique used in the project "Development of a business intelligence solution to support decision making in the Learning Circles Project," explaining why of their choice and how it was used Key Word-Business Intelligence, Data Warehouse, Data Staging Area, ETL Process. I. INTRODUCCIÓN El proceso de extracción, transformación y carga-ETL (Extraction, Transformation and Load) es una de las actividades técnicas más críticas en el desarrollo de soluciones de inteligencia de negocios-BI (Business Intelligence) [1][2]. Hace parte del componente de integración y, de su implementación adecuada dependen la integridad, uniformidad, consistencia y disponibilidad de los datos utilizados en el componente de análisis de una solución de BI. Su función es extraer, limpiar, transformar, resumir, y formatear los datos que se almacenarán en la bodega de datos de la solución de BI [3][4][5]. La construcción del ETL puede dividirse en tres subprocesos o componentes: componente de extracción, componente de transformación y componente de carga. En la Tabla 1 se presenta la descripción de cada uno de estos componentes identificando los elementos objetivo, las operaciones realizadas, y los resultados esperados.},
   author = {Alexander Bustamante Martínez and Ernesto Amaru and Galvis Lista and Luis Carlos Gómez Flórez},
   issn = {0122-1701},
   issue = {1},
   journal = {Scientia et Technica Año XVIII},
   month = {3},
   title = {ETL Processes modeling techniques: an alternatives review and its application in a BI solution development project},
   volume = {18},
   year = {2013},
}

@misc{BuscadorAmbiental,
   title = {Buscador Ambiental},
   url = {https://www.buscadorambiental.cl/buscador/#/},
}

@misc{Ley20600,
   title = {Ley Chile - Ley 20600 - Biblioteca del Congreso Nacional},
   url = {https://www.bcn.cl/leychile/navegar?idNorma=1041361&idParte=9269911},
}

% ETL
@article{ETL1,
   abstract = {In this paper, we discuss the state of the art and current trends in designing and optimizing ETL workflows. We explain the existing techniques for: (1) constructing a conceptual and a logical model of an ETL workflow, (2) its corresponding physical implementation, and (3) its optimization, illustrated by examples. The discussed techniques are analyzed w.r.t. their advantages, disadvantages, and challenges in the context of metrics such as autonomous behavior, support for quality metrics, and support for ETL activities as user-defined functions. We draw conclusions on still open research and technological issues in the field of ETL. Finally, we propose a theoretical ETL framework for ETL optimization.},
   author = {Syed Muhammad Fawad Ali and Robert Wrembel},
   doi = {10.1007/S00778-017-0477-2/FIGURES/18},
   issn = {0949877X},
   issue = {6},
   journal = {VLDB Journal},
   keywords = {ETL conceptual design,ETL logical design,ETL optimization,ETL physical implementation,ETL workflow},
   month = {12},
   pages = {777-801},
   publisher = {Springer New York LLC},
   title = {From conceptual design to performance optimization of ETL workflows: current state of research and open problems},
   volume = {26},
   url = {https://link.springer.com/article/10.1007/s00778-017-0477-2},
   year = {2017},
}

@article{riesgochat1,
   abstract = {Recent advances in large language models (LLMs), such as ChatGPT, have led to highly sophisticated conversation agents. However, these models suffer from "hallucinations," where the model generates false or fabricated information. Addressing this challenge is crucial, particularly with AI-driven platforms being adopted across various sectors. In this paper, we propose a novel method to recognize and flag instances when LLMs perform outside their domain knowledge, and ensuring users receive accurate information. We find that the use of context combined with embedded tags can successfully combat hallucinations within generative language models. To do this, we baseline hallucination frequency in no-context prompt-response pairs using generated URLs as easily-tested indicators of fabricated data. We observed a significant reduction in overall hallucination when context was supplied along with question prompts for tested generative engines. Lastly, we evaluated how placing tags within contexts impacted model responses and were able to eliminate hallucinations in responses with 98.88% effectiveness.},
   author = {Philip Feldman and James R. Foulds and Shimei Pan},
   isbn = {2306.06085v1},
   month = {6},
   title = {Trapping LLM Hallucinations Using Tagged Context Prompts},
   url = {https://arxiv.org/abs/2306.06085v1},
   year = {2023},
}
